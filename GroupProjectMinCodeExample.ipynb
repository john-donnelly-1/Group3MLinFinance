{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file I load below is a combined output generated from the two separate files on credit rating and ratios - all downloaded from the Wharton DB. I do not show the path how I got there because this should ultimately be part of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>cusip</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>adate</th>\n",
       "      <th>qdate</th>\n",
       "      <th>public_date</th>\n",
       "      <th>splticrm</th>\n",
       "      <th>bm</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>...</th>\n",
       "      <th>dltt_be</th>\n",
       "      <th>debt_assets</th>\n",
       "      <th>debt_capital</th>\n",
       "      <th>de_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>curr_ratio</th>\n",
       "      <th>at_turn</th>\n",
       "      <th>ptb</th>\n",
       "      <th>PEG_trailing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2009-11-30</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>A</td>\n",
       "      <td>0.252</td>\n",
       "      <td>4.976</td>\n",
       "      <td>13.353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.949</td>\n",
       "      <td>1.875</td>\n",
       "      <td>2.409</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.466</td>\n",
       "      <td>4.145</td>\n",
       "      <td>1.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2009-11-30</td>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>A</td>\n",
       "      <td>0.252</td>\n",
       "      <td>5.323</td>\n",
       "      <td>14.285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.949</td>\n",
       "      <td>1.875</td>\n",
       "      <td>2.409</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.466</td>\n",
       "      <td>4.434</td>\n",
       "      <td>1.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2009-11-30</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>A</td>\n",
       "      <td>0.252</td>\n",
       "      <td>5.556</td>\n",
       "      <td>14.911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.949</td>\n",
       "      <td>1.875</td>\n",
       "      <td>2.409</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.466</td>\n",
       "      <td>4.628</td>\n",
       "      <td>1.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>A</td>\n",
       "      <td>0.233</td>\n",
       "      <td>5.381</td>\n",
       "      <td>15.909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.739</td>\n",
       "      <td>2.237</td>\n",
       "      <td>2.245</td>\n",
       "      <td>0.453</td>\n",
       "      <td>4.515</td>\n",
       "      <td>1.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>A</td>\n",
       "      <td>0.233</td>\n",
       "      <td>4.692</td>\n",
       "      <td>13.871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.739</td>\n",
       "      <td>2.237</td>\n",
       "      <td>2.245</td>\n",
       "      <td>0.453</td>\n",
       "      <td>3.937</td>\n",
       "      <td>1.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>A</td>\n",
       "      <td>0.233</td>\n",
       "      <td>4.461</td>\n",
       "      <td>13.189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.739</td>\n",
       "      <td>2.237</td>\n",
       "      <td>2.245</td>\n",
       "      <td>0.453</td>\n",
       "      <td>3.743</td>\n",
       "      <td>1.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-07-31</td>\n",
       "      <td>A</td>\n",
       "      <td>0.275</td>\n",
       "      <td>4.430</td>\n",
       "      <td>13.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.257</td>\n",
       "      <td>1.821</td>\n",
       "      <td>1.838</td>\n",
       "      <td>0.492</td>\n",
       "      <td>3.805</td>\n",
       "      <td>1.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>A</td>\n",
       "      <td>0.275</td>\n",
       "      <td>4.093</td>\n",
       "      <td>12.645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.257</td>\n",
       "      <td>1.821</td>\n",
       "      <td>1.838</td>\n",
       "      <td>0.492</td>\n",
       "      <td>3.516</td>\n",
       "      <td>1.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>A</td>\n",
       "      <td>0.275</td>\n",
       "      <td>5.033</td>\n",
       "      <td>15.549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.257</td>\n",
       "      <td>1.821</td>\n",
       "      <td>1.838</td>\n",
       "      <td>0.492</td>\n",
       "      <td>4.323</td>\n",
       "      <td>1.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10104</td>\n",
       "      <td>68389X10</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>2010-10-31</td>\n",
       "      <td>A</td>\n",
       "      <td>0.296</td>\n",
       "      <td>5.046</td>\n",
       "      <td>16.860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.568</td>\n",
       "      <td>2.061</td>\n",
       "      <td>2.077</td>\n",
       "      <td>0.488</td>\n",
       "      <td>4.551</td>\n",
       "      <td>1.632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno     cusip Ticker      adate      qdate public_date splticrm     bm  \\\n",
       "0   10104  68389X10   ORCL 2009-05-31 2009-11-30  2010-01-31        A  0.252   \n",
       "1   10104  68389X10   ORCL 2009-05-31 2009-11-30  2010-02-28        A  0.252   \n",
       "2   10104  68389X10   ORCL 2009-05-31 2009-11-30  2010-03-31        A  0.252   \n",
       "3   10104  68389X10   ORCL 2009-05-31 2010-02-28  2010-04-30        A  0.233   \n",
       "4   10104  68389X10   ORCL 2009-05-31 2010-02-28  2010-05-31        A  0.233   \n",
       "5   10104  68389X10   ORCL 2009-05-31 2010-02-28  2010-06-30        A  0.233   \n",
       "6   10104  68389X10   ORCL 2010-05-31 2010-05-31  2010-07-31        A  0.275   \n",
       "7   10104  68389X10   ORCL 2010-05-31 2010-05-31  2010-08-31        A  0.275   \n",
       "8   10104  68389X10   ORCL 2010-05-31 2010-05-31  2010-09-30        A  0.275   \n",
       "9   10104  68389X10   ORCL 2010-05-31 2010-08-31  2010-10-31        A  0.296   \n",
       "\n",
       "      ps     pcf  ...  dltt_be  debt_assets  debt_capital  de_ratio  \\\n",
       "0  4.976  13.353  ...    0.451        0.485         0.338     0.949   \n",
       "1  5.323  14.285  ...    0.451        0.485         0.338     0.949   \n",
       "2  5.556  14.911  ...    0.451        0.485         0.338     0.949   \n",
       "3  5.381  15.909  ...    0.443        0.493         0.346     0.982   \n",
       "4  4.692  13.871  ...    0.443        0.493         0.346     0.982   \n",
       "5  4.461  13.189  ...    0.443        0.493         0.346     0.982   \n",
       "6  4.430  13.687  ...    0.369        0.493         0.334     0.986   \n",
       "7  4.093  12.645  ...    0.369        0.493         0.334     0.986   \n",
       "8  5.033  15.549  ...    0.369        0.493         0.334     0.986   \n",
       "9  5.046  16.860  ...    0.428        0.498         0.352     1.006   \n",
       "\n",
       "   cash_ratio  quick_ratio  curr_ratio  at_turn    ptb  PEG_trailing  \n",
       "0       1.875        2.409       2.409    0.466  4.145         1.045  \n",
       "1       1.875        2.409       2.409    0.466  4.434         1.117  \n",
       "2       1.875        2.409       2.409    0.466  4.628         1.165  \n",
       "3       1.739        2.237       2.245    0.453  4.515         1.545  \n",
       "4       1.739        2.237       2.245    0.453  3.937         1.348  \n",
       "5       1.739        2.237       2.245    0.453  3.743         1.282  \n",
       "6       1.257        1.821       1.838    0.492  3.805         1.311  \n",
       "7       1.257        1.821       1.838    0.492  3.516         1.212  \n",
       "8       1.257        1.821       1.838    0.492  4.323         1.489  \n",
       "9       1.568        2.061       2.077    0.488  4.551         1.632  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SP500_LongTermCreditRating_Ratios_combined.csv', sep=',', \n",
    "                 parse_dates=['adate', 'qdate', 'public_date'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30119, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume (for whatever random reason) I believe that debt-ebitda ratio, debt-capital ratio, and book-to-market ratio are the most relevant features to estimate a company's long-term credit rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these columns, I need to have a full set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_ebitda     145\n",
       "debt_capital    279\n",
       "bm              671\n",
       "splticrm          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NA/missing values for relevant columns\n",
    "selCols = ['debt_ebitda', 'debt_capital', 'bm', 'splticrm']\n",
    "df[selCols].isnull().sum()  # alternatively: df[selCols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_ebitda     float64\n",
       "debt_capital    float64\n",
       "bm              float64\n",
       "splticrm         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[selCols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above I see that I will need to address the question of missing data (either impute them or delete the corresponding samples). See further down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop the two rows where credit rating is 'CCC' or as this is too small a sample to be considered (only 2 and 4 appearances, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['splticrm'] != 'CCC']\n",
    "df = df[df['splticrm'] != 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30113, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign columns to X (feature matrix) and y (response vector). The latter we need to transform into numeric categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debt_ebitda</th>\n",
       "      <th>debt_capital</th>\n",
       "      <th>bm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.153</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.153</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.224</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.224</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debt_ebitda  debt_capital     bm\n",
       "0        1.153         0.338  0.252\n",
       "1        1.153         0.338  0.252\n",
       "2        1.153         0.338  0.252\n",
       "3        1.224         0.346  0.233\n",
       "4        1.224         0.346  0.233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign feature columns to X\n",
    "X = df[selCols].iloc[:, :-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3797 1943  990  296 5649 3322  489 3955 4831  199   50  143  410 1069\n",
      " 1648 1096  226]\n",
      "Index(['A', 'A+', 'AA-', 'AAA', 'BBB', 'BBB-', 'AA', 'A-', 'BBB+', 'AA+',\n",
      "       'CCC+', 'B-', 'B+', 'BB-', 'BB+', 'BB', 'B'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Assign response columns to y\n",
    "y = pd.factorize(df['splticrm'])[0]\n",
    "print(np.bincount(y))\n",
    "print(pd.factorize(df['splticrm'])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this example simple, I decide to drop the affected rows. For your project the expectation is that you specifically address this issue and fill/impute missing values based on your economic reasoning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Scikit-learn's pipeline tool to get some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.91\n",
      "Test score:       0.95\n",
      "Best parameters: {'classifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'imputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0), 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline object with standard scaler and RandomForest estimator\n",
    "pipe = Pipeline([('imputer', SimpleImputer()),\n",
    "                 ('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Define the hyperparameter values to be tested\n",
    "param_grid = [{'imputer': [SimpleImputer(strategy='mean')],\n",
    "               'scaler': [StandardScaler()],\n",
    "               'classifier': [RandomForestClassifier(criterion='gini')],\n",
    "               'classifier__max_depth': [1, 10, 100, None],\n",
    "               'classifier__min_samples_split': [2, 10, 20]}]\n",
    "\n",
    "# Run brute-force grid search\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5, n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best CV accuracy: {:.2f}'.format(gs.best_score_))\n",
    "print('Test score:       {:.2f}'.format(gs.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.20\n",
      "Test score:       0.20\n",
      "Best parameters: {'classifier': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'classifier__C': 100, 'imputer': KNNImputer(add_indicator=False, copy=True, metric='nan_euclidean',\n",
      "           missing_values=nan, n_neighbors=5, weights='uniform'), 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline object with standard scaler and LogisticRegression estimator\n",
    "pipe = Pipeline([('imputer', KNNImputer()),\n",
    "                 ('scaler', StandardScaler()), \n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "# Define the hyperparameter values to be tested\n",
    "param_grid = [{'imputer': [KNNImputer(n_neighbors=5)],\n",
    "               'scaler': [StandardScaler()],\n",
    "               'classifier': [LogisticRegression(max_iter=1000)],\n",
    "               'classifier__C': [1, 100, 1000]}]\n",
    "\n",
    "# Run brute-force grid search\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5, n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best CV accuracy: {:.2f}'.format(gs.best_score_))\n",
    "print('Test score:       {:.2f}'.format(gs.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.20\n",
      "Test score:       0.21\n",
      "Best parameters: {'classifier': LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'classifier__C': 1000, 'imputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0), 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline object with standard scaler and LogisticRegression estimator\n",
    "pipe = Pipeline([('imputer', SimpleImputer()),\n",
    "                 ('scaler', StandardScaler()), \n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "# Define the hyperparameter values to be tested\n",
    "param_grid = [{'imputer': [SimpleImputer(strategy='mean')],\n",
    "               'scaler': [StandardScaler()],\n",
    "               'classifier': [LogisticRegression(max_iter=1000)],\n",
    "               'classifier__C': [1, 100, 1000]}]\n",
    "\n",
    "# Run brute-force grid search\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5, n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best CV accuracy: {:.2f}'.format(gs.best_score_))\n",
    "print('Test score:       {:.2f}'.format(gs.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.47\n",
      "Test score:       0.47\n",
      "Best parameters: {'classifier': SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__C': 100, 'classifier__gamma': 10, 'imputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0), 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline object with standard scaler and SVC estimator\n",
    "pipe = Pipeline([('imputer', SimpleImputer()),\n",
    "                 ('scaler', StandardScaler()), \n",
    "                 ('classifier', SVC())])\n",
    "\n",
    "# Define the hyperparameter values to be tested\n",
    "param_grid = [{'imputer': [SimpleImputer(strategy='mean')],\n",
    "               'scaler': [StandardScaler()],\n",
    "               'classifier': [SVC(kernel='rbf')],\n",
    "               'classifier__gamma': [1, 10],\n",
    "               'classifier__C': [10, 100]}]\n",
    "\n",
    "# Run brute-force grid search\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5, n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best CV accuracy: {:.2f}'.format(gs.best_score_))\n",
    "print('Test score:       {:.2f}'.format(gs.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below is a code snippet in case multiple classifiers should be run within the same pipeline. However, as noted during class, this might quickly get very time consuming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.47\n",
      "Test score:       0.47\n",
      "Best parameters: {'classifier': SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__C': 100, 'classifier__gamma': 10, 'imputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0), 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "pipe = Pipeline([('imputer', SimpleImputer()),\n",
    "                 ('scaler', StandardScaler()), \n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = [{'imputer': [SimpleImputer(strategy='mean')],\n",
    "               'scaler': [StandardScaler()],\n",
    "               'classifier': [LogisticRegression(max_iter=1000)],\n",
    "               'classifier__C': [1, 100, 1000]},\n",
    "              {'imputer': [SimpleImputer(strategy='mean')],\n",
    "               'scaler': [StandardScaler()],\n",
    "               'classifier': [SVC(kernel='rbf')],\n",
    "               'classifier__gamma': [1, 10],\n",
    "               'classifier__C': [10, 100]}]\n",
    "\n",
    "# Run grid search\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid.best_score_))\n",
    "print('Test score:       {:.2f}'.format(grid.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ultimately, you will need to analyze your results using appropriate output, metrics, and plots.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
